import gradio as gr
from gradio.themes.base import Base
from Database_interface import DataBaseInterface
from FileTextLoader import FileTextLoader
from langchain_openai import OpenAI
import secret_key

# Database Interface Setup
indexName = "alelladoc"
dbName = "Randomcuments"
collectionName = "collection_of_text_blobs"

TextLoader = FileTextLoader()


PineConeinterface = DataBaseInterface(indexName, secret_key.openai_key,
                                      secret_key.pinecone_key,
                                      secret_key.mongodb_uri, dbName,
                                      collectionName)

# Define a function to process the uploaded files
def process_files(files):
    if files:
        text_data_from_files = TextLoader.load_all_files(files)
        PineConeinterface.import_documents(text_data_from_files)
        return "Files processed successfully."
    return "No files to process."

# Define a function to query the database with a question
def query_question(question):
    documents = PineConeinterface.query_data(question)
    output1= analyze_documents(documents, question)

 #   output1, output2 = analyze_documents(documents, question)
 #   return output1, output2
    return output1

def analyze_documents(documents, question):
    llm = OpenAI(openai_api_key=secret_key.openai_key,
                 model_name="gpt-4-turbo-mini",
                 temperature=0)
    as_output = ""
    retriever_output = ""
    for document in documents:
        as_output = as_output.join(document)
        query_to_ai = "Try to answer this question with the text you are provided".join(question)
        #retriever_output = retriever_output.join(llm.invoke(query_to_ai.join(as_output)))

    return as_output#, retriever_output

# Gradio Interface
with gr.Blocks(theme=Base(), title="SemantiLibrary") as demo:
    gr.Markdown("# Question Answering App using Vector Search")
    
    # File upload component
    file_upload = gr.File(label="Upload Files (TXT, PDF, DOCX)", file_count="multiple", type="filepath")
    
    # Button for processing files
    process_button = gr.Button("Process Files", variant="primary")
    
    # Status output for file processing
    process_status = gr.Textbox(lines=1, max_lines=1, label="Processing Status")
    
    # Input for text question
    textbox = gr.Textbox(label="Enter your Question:")
    
    # Button for querying the processed files
    query_button = gr.Button("Submit Question", variant="secondary")
    
    # Output boxes for the query results
    with gr.Column():
        output1 = gr.Textbox(lines=1, max_lines=10, label="File retrieved in the database")
       # output2 = gr.Textbox(lines=1, max_lines=10, label="Output generated by Langchain Vector Search")

    # Connect the process button to the file processing function
    process_button.click(process_files, inputs=file_upload, outputs=process_status)
    
    # Connect the query button to the question answering function
    #query_button.click(query_question, inputs=textbox, outputs=[output1, output2])
    query_button.click(query_question, inputs=textbox, outputs=output1)

# Launch the app
demo.launch()
